xTrain = cbind(xTrain, xTrain^2)
xPredict = cbind(xPredict, xPredict^2)
colnames(xTrain) = column_names
colnames(xPredict) = column_names
xTrain = xTrain[,-21]# drop yr0fPts since it's a linear combination of 6 other attributes
xPredict = xPredict[,-21]
#fit and evaluate the model
a = train(xTrain, log(yTrain))
a # this is the solution to the normal equation
table = attribute_table_2(xTrain, log(yTrain))
table[rev(order(table$trainMSE)),]# table of errors using leave-one-out regression, sorted by Train MSE
table[rev(order(table$validationMSE)),]# table of errors using leave-one-out regression, sorted by Validation MSE
table = attribute_table_2(Train[,3:22], log(yTrain), quadratic = TRUE)
table[rev(order(table$trainMSE)),]         # here we do the same thing, but for each attribute,
table[rev(order(table$validationMSE)),]    # x and x^2 are a package deal (both or neither)
#predicting
X=as.matrix(cbind(rep(1,nrow(xPredict)),xPredict))
yHat = X %*% a
prediction = cbind(d2021[,1], exp(yHat))
colnames(prediction) <- c("Name", "ProjPts")
prediction = as.data.frame(prediction)
prediction[,2]<-as.numeric(prediction[,2])
prediction[rev(order(prediction$ProjPts)),] #prediction on 2021 data
#fit and evaluate the model
a = train(xTrain, log(yTrain))
a # this is the solution to the normal equation
table = attribute_table_2(xTrain, log(yTrain))
table[rev(order(table$trainMSE)),]# table of errors using leave-one-out regression, sorted by Train MSE
table[rev(order(table$validationMSE)),]# table of errors using leave-one-out regression, sorted by Validation MSE
table = attribute_table_2(Train[,3:22], log(yTrain), quadratic = TRUE)
table[rev(order(table$trainMSE)),]         # here we do the same thing, but for each attribute,
table[rev(order(table$trainMSE)),]# table of errors using leave-one-out regression, sorted by Train MSE
setwd('C:\\Users\\Daniel\\Desktop\\DataMiningFinalProj')
# this function will quickly assemble the data into our desired format by intelligently
# merging 2 data tables and then dropping certain columns
getdata <- function(year, prediction=FALSE, positive_y=FALSE) {
yr0rush <- read.csv(paste(year,"rush.csv", sep = ""),stringsAsFactors=FALSE, sep=",")
yr0rec <- read.csv(paste(year,"rec.csv", sep = ""),stringsAsFactors=FALSE, sep=",")
if(!prediction){
year = year + 1
yr1rush <- read.csv(paste(year,"rush.csv", sep = ""),stringsAsFactors=FALSE, sep=",")
yr1rec <- read.csv(paste(year,"rec.csv", sep = ""),stringsAsFactors=FALSE, sep=",")
}
n = nrow(yr0rush)
Tgt <- rep(0,n)
Rec <- rep(0,n)
Ctch. <- rep(NA,n)
RecYds <- rep(0,n)
Y.R <- rep(NA,n)
RecTD <- rep(0,n)
Rec1D <- rep(0,n)
Y.Tgt <- rep(NA,n)
R.G <- rep(0,n)
RecY.G <- rep(0,n)
yr0fPts <- rep(0,n)
if(!prediction){
yr1fPts <- rep(0,n)
g <- rep(0,n)
}
if(!prediction){
data = cbind(yr0rush, Tgt, Rec, Ctch., RecYds, Y.R, RecTD, Rec1D, Y.Tgt, R.G, RecY.G, yr0fPts, g, yr1fPts)
} else {
data = cbind(yr0rush, Tgt, Rec, Ctch., RecYds, Y.R, RecTD, Rec1D, Y.Tgt, R.G, RecY.G, yr0fPts)
}
for (i in 1:n) {
tag = data[i,16]
#fill in receiving data
rowNum = which(yr0rec$Tag == tag)
if (length(rowNum)) {
data[i,17] = yr0rec[rowNum, 8]
data[i,18] = yr0rec[rowNum, 9]
data[i,19] = yr0rec[rowNum, 10]
data[i,20] = yr0rec[rowNum, 11]
data[i,21] = yr0rec[rowNum, 12]
data[i,22] = yr0rec[rowNum, 13]
data[i,23] = yr0rec[rowNum, 14]
data[i,24] = yr0rec[rowNum, 16]
data[i,25] = yr0rec[rowNum, 17]
data[i,26] = yr0rec[rowNum, 18]
}
#fill in yr0 fantasy data
data[i,27] = data[i,9]/10 + data[i,10]*6 - data[i,15]*1.2 + data[i,18] + data[i,20]/10 + data[i,22]*6
#fill in yr1 fantasy data and games
if (!prediction){
points = 0
rowNum = which(yr1rush$Tag == tag)
if (length(rowNum)) {
data[i,28] = yr1rush[rowNum, 6]
points = points + yr1rush[rowNum,9]/10 + yr1rush[rowNum,10]*6 - yr1rush[rowNum,15]*1.2
}
rowNum = which(yr1rec$Tag == tag)
if (length(rowNum)) {
points = points + yr1rec[rowNum,9] + yr1rec[rowNum,11]/10 + yr1rec[rowNum,13]*6
}
data[i,29] = points
}
}
#drop anyone who's not an RB
data = subset(data,Pos=='RB')
#drop anyone who didn't do anything the next year
if (!prediction) {
data = subset(data,g!="0") # how does this work with or without the quotes
}
#drop unnecessary columns
if (!prediction) {
data = subset(data, select = -c(Rk,Pos,Lng,Tag,g))
} else {
data = subset(data, select = -c(Rk,Pos,Lng,Tag))
}
#erase percentage signs
data$Ctch. <- gsub("\\%","",data$Ctch.)
#convert strings to ints
for (i in 3:23) {
data[,i]<-as.numeric(data[,i])
}
if(!prediction){
data[,24]<-as.numeric(data[,24])
}
#convert NA to 0
data[is.na(data)] = 0
#drop non-positive y
if (!prediction && positive_y) {
data = subset(data,yr1fPts>0)
}
return(data)
}
# this method will train a regression model and return the weight vector
train <- function(X, y) {
X <- as.matrix(cbind(rep(1,nrow(X)),X))
y <- as.vector(y)
a = solve(t(X) %*% X, t(X) %*% y, tol = 1e-20)
return(a)
}
# this method will compute the train and test error
error <- function(xTrain, yTrain, xTest, yTest) {
a = train(xTrain, yTrain)
X <- as.matrix(cbind(rep(1,nrow(xTrain)),xTrain))
y <- as.vector(yTrain)
yhat = X %*% a
error = y - yhat
sse = sum(error*error)
trainMSE = sse/length(error)
X <- as.matrix(cbind(rep(1,nrow(xTest)),xTest))
y <- as.vector(yTest)
yhat = X %*% a
error = y - yhat
sse = sum(error*error)
testMSE = sse/length(error)
return(c(trainMSE, testMSE))
}
# this method will return a table displaying the training error and the testing
# error resulting from leaving each attribute out
attribute_table <- function(xTrain, yTrain, xTest, yTest) {
Attribute <- colnames(xTrain)
trainMSE <- rep(0,ncol(xTrain))
testMSE <- rep(0,ncol(xTrain))
for (i in 1:ncol(xTrain)){
vec = error(xTrain[,-i], yTrain, xTest[,-i], yTest)
trainMSE[i] = vec[1]
testMSE[i] = vec[2]
}
df <- data.frame(Attribute, trainMSE, testMSE)
vec = error(xTrain, yTrain, xTest, yTest)
df <- rbind(data.frame(Attribute = "None", trainMSE = vec[1], testMSE = vec[2]), df)
return(df)
}
# this method will perform 5-fold cross-validation and return a table displaying
# the training error and the validation error resulting from leaving each attribute out
attribute_table_2 <- function(X, y, quadratic=FALSE) {
n = nrow(X)
order = sample(1:n)
X = X[order, ] #shuffle X
y = y[order] #shuffle y
X1 = X[0:floor(n/5),]
y1 = y[0:floor(n/5)]
X2 = X[floor(n/5):floor(2*n/5),]
y2 = y[floor(n/5):floor(2*n/5)]
X3 = X[floor(2*n/5):floor(3*n/5),]
y3 = y[floor(2*n/5):floor(3*n/5)]
X4 = X[floor(3*n/5):floor(4*n/5),]
y4 = y[floor(3*n/5):floor(4*n/5)]
X5 = X[floor(4*n/5):n,]
y5 = y[floor(4*n/5):n]
if (quadratic) {
t1 = helper(rbind(X2,X3,X4,X5), c(y2,y3,y4,y5), X1, y1)
t2 = helper(rbind(X1,X3,X4,X5), c(y1,y3,y4,y5), X2, y2)
t3 = helper(rbind(X1,X2,X4,X5), c(y1,y2,y4,y5), X3, y3)
t4 = helper(rbind(X1,X2,X3,X5), c(y1,y2,y3,y5), X4, y4)
t5 = helper(rbind(X1,X2,X3,X4), c(y1,y2,y3,y4), X5, y5)
} else {
t1 = attribute_table(rbind(X2,X3,X4,X5), c(y2,y3,y4,y5), X1, y1)
t2 = attribute_table(rbind(X1,X3,X4,X5), c(y1,y3,y4,y5), X2, y2)
t3 = attribute_table(rbind(X1,X2,X4,X5), c(y1,y2,y4,y5), X3, y3)
t4 = attribute_table(rbind(X1,X2,X3,X5), c(y1,y2,y3,y5), X4, y4)
t5 = attribute_table(rbind(X1,X2,X3,X4), c(y1,y2,y3,y4), X5, y5)
}
res = cbind(t1[,1],(t1[,2:3]+t2[,2:3]+t3[,2:3]+t4[,2:3]+t5[,2:3])/5)
colnames(res)[3] = "validationMSE"
return(res)
}
helper <- function(xTrain, yTrain, xTest, yTest) {
Attribute <- colnames(xTrain)
trainMSE <- rep(0,ncol(xTrain))
testMSE <- rep(0,ncol(xTrain))
for (i in 1:ncol(xTrain)){
vec = error(cbind(xTrain[,-i], xTrain[,-i]^2), yTrain, cbind(xTest[,-i], xTest[,-i]^2), yTest)
trainMSE[i] = vec[1]
testMSE[i] = vec[2]
}
df <- data.frame(Attribute, trainMSE, testMSE)
vec = error(cbind(xTrain, xTrain^2), yTrain, cbind(xTest, xTest^2), yTest)
df <- rbind(data.frame(Attribute = "None", trainMSE = vec[1], testMSE = vec[2]), df)
return(df)
}
# create our train, test, and predict data
d2011 = getdata(2011)
d2012 = getdata(2012)
d2013 = getdata(2013)
d2014 = getdata(2014)
d2015 = getdata(2015)
d2016 = getdata(2016)
d2017 = getdata(2017)
d2018 = getdata(2018)
d2019 = getdata(2019)
d2020 = getdata(2020)
d2021 = getdata(2021, prediction = TRUE)
Train = rbind(d2011, d2012, d2013, d2014, d2015, d2016, d2017, d2018)
Test = rbind(d2019, d2020)
xTrain = Train[,3:23]
yTrain = Train[,24]
xTest = Test[,3:23]
yTest = Test[,24]
xPredict = d2021[,3:23]
xTrain = xTrain[,-21]
xTest = xTest[,-21]  # drop yr0fPts since it's a linear combination of 6 other attributes
xPredict = xPredict[,-21]
#fit and evaluate the model
a = train(xTrain, yTrain)
a # this is the solution to the normal equation
table = attribute_table(xTrain, yTrain, xTest, yTest)
table[rev(order(table$trainMSE)),]# table of errors using leave-one-out regression, sorted by Train MSE
table[rev(order(table$testMSE)),]# table of errors using leave-one-out regression, sorted by Test MSE
#predicting
X=as.matrix(cbind(rep(1,nrow(xPredict)),xPredict))
yHat = X %*% a
prediction = cbind(d2021[,1], yHat)
colnames(prediction) <- c("Name", "ProjPts")
prediction = as.data.frame(prediction)
prediction[,2]<-as.numeric(prediction[,2])
prediction[rev(order(prediction$ProjPts)),] #prediction on 2021 data
# create our train, test, and predict data
d2011 = getdata(2011, positive_y=TRUE)
d2012 = getdata(2012, positive_y=TRUE)
d2013 = getdata(2013, positive_y=TRUE)
d2014 = getdata(2014, positive_y=TRUE)
d2015 = getdata(2015, positive_y=TRUE)
d2016 = getdata(2016, positive_y=TRUE)
d2017 = getdata(2017, positive_y=TRUE)
d2018 = getdata(2018, positive_y=TRUE)
d2019 = getdata(2019, positive_y=TRUE)
d2020 = getdata(2020, positive_y=TRUE)
d2021 = getdata(2021, prediction = TRUE)
Train = rbind(d2011, d2012, d2013, d2014, d2015, d2016, d2017, d2018)
Test = rbind(d2019, d2020)
xTrain = Train[,3:23]
yTrain = Train[,24]
xTest = Test[,3:23]
yTest = Test[,24]
xPredict = d2021[,3:23]
xTrain = xTrain[,-21]
xTest = xTest[,-21]  # drop yr0fPts since it's a linear combination of 6 other attributes
xPredict = xPredict[,-21]
#normalize
constants = matrix(rep(0,40), nrow=20)
X = rbind(xTrain, xTest, xPredict)
for (i in 1:20){
constants[i,] = c(mean(X[,i]),sd(X[,i]))
}
standardization <- function(df) {
for (i in 1:20) {
mean = constants[i,1]
sd = constants[i,2]
df[,i] = (df[,i] - mean) / sd
}
return(df)
}
xTrain <- standardization(xTrain)
xTest <- standardization(xTest)
xPredict <- standardization(xPredict)
#fit and evaluate the model
a = train(xTrain, log(yTrain))
a # this is the solution to the normal equation
table = attribute_table(xTrain, log(yTrain), xTest, log(yTest))
table[rev(order(table$trainMSE)),]# table of errors using leave-one-out regression, sorted by Train MSE
table[rev(order(table$testMSE)),]# table of errors using leave-one-out regression, sorted by Test MSE
a # this is the solution to the normal equation
table = attribute_table(xTrain, log(yTrain), xTest, log(yTest))
table[rev(order(table$trainMSE)),]# table of errors using leave-one-out regression, sorted by Train MSE
table[rev(order(table$testMSE)),]# table of errors using leave-one-out regression, sorted by Test MSE
#predicting
X=as.matrix(cbind(rep(1,nrow(xPredict)),xPredict))
yHat = X %*% a
prediction = cbind(d2021[,1], exp(yHat))
colnames(prediction) <- c("Name", "ProjPts")
prediction = as.data.frame(prediction)
prediction[,2]<-as.numeric(prediction[,2])
prediction[rev(order(prediction$ProjPts)),] #prediction on 2021 data
colnames(xTrain)
xTrain = Train[,3:23]
colnames(xTrain)
cat(paste(colnames(xTrain)),sep="")
xTrain = Train[,3:23]
for (e in colnames(xTrain)){print(e)}
# create our train, test, and predict data
d2011 = getdata(2011, positive_y=TRUE)
d2012 = getdata(2012, positive_y=TRUE)
d2013 = getdata(2013, positive_y=TRUE)
d2014 = getdata(2014, positive_y=TRUE)
d2015 = getdata(2015, positive_y=TRUE)
d2016 = getdata(2016, positive_y=TRUE)
d2017 = getdata(2017, positive_y=TRUE)
d2018 = getdata(2018, positive_y=TRUE)
d2019 = getdata(2019, positive_y=TRUE)
d2020 = getdata(2020, positive_y=TRUE)
d2021 = getdata(2021, prediction = TRUE)
Train = rbind(d2011, d2012, d2013, d2014, d2015, d2016, d2017, d2018, d2019, d2020)
xTrain = Train[,3:23]
yTrain = Train[,24]
xPredict = d2021[,3:23]
vec1 = colnames(xTrain)
vec2 = paste(vec1, "^2", sep="")
column_names = c(vec1,vec2)
xTrain = cbind(xTrain, xTrain^2)
xPredict = cbind(xPredict, xPredict^2)
colnames(xTrain) = column_names
colnames(xPredict) = column_names
xTrain = xTrain[,-21]# drop yr0fPts since it's a linear combination of 6 other attributes
xPredict = xPredict[,-21]
#fit and evaluate the model
a = train(xTrain, log(yTrain))
a # this is the solution to the normal equation
table = attribute_table_2(xTrain, log(yTrain))
table[rev(order(table$trainMSE)),]# table of errors using leave-one-out regression, sorted by Train MSE
table[rev(order(table$validationMSE)),]# table of errors using leave-one-out regression, sorted by Validation MSE
table = attribute_table_2(xTrain, log(yTrain))
table[rev(order(table$trainMSE)),]# table of errors using leave-one-out regression, sorted by Train MSE
table[rev(order(table$validationMSE)),]# table of errors using leave-one-out regression, sorted by Validation MSE
table = attribute_table_2(xTrain, log(yTrain))
table[rev(order(table$trainMSE)),]# table of errors using leave-one-out regression, sorted by Train MSE
table[rev(order(table$validationMSE)),]# table of errors using leave-one-out regression, sorted by Validation MSE
#fit and evaluate the model
a = train(xTrain, log(yTrain))
a # this is the solution to the normal equation
table = attribute_table_2(xTrain, log(yTrain))
table[rev(order(table$trainMSE)),]# table of errors using leave-one-out regression, sorted by Train MSE
table[rev(order(table$validationMSE)),]# table of errors using leave-one-out regression, sorted by Validation MSE
table = attribute_table_2(Train[,3:22], log(yTrain), quadratic = TRUE)
table[rev(order(table$trainMSE)),]         # here we do the same thing, but for each attribute,
table[rev(order(table$validationMSE)),]    # x and x^2 are a package deal (both or neither)
table = attribute_table_2(Train[,3:22], log(yTrain), quadratic = TRUE)
table[rev(order(table$trainMSE)),]         # here we do the same thing, but for each attribute,
table[rev(order(table$validationMSE)),]    # x and x^2 are a package deal (both or neither)
# create our train, test, and predict data
d2011 = getdata(2011, positive_y=TRUE)
d2012 = getdata(2012, positive_y=TRUE)
d2013 = getdata(2013, positive_y=TRUE)
d2014 = getdata(2014, positive_y=TRUE)
d2015 = getdata(2015, positive_y=TRUE)
d2016 = getdata(2016, positive_y=TRUE)
d2017 = getdata(2017, positive_y=TRUE)
d2018 = getdata(2018, positive_y=TRUE)
d2019 = getdata(2019, positive_y=TRUE)
d2020 = getdata(2020, positive_y=TRUE)
d2021 = getdata(2021, prediction = TRUE)
Train = rbind(d2011, d2012, d2013, d2014, d2015, d2016, d2017, d2018, d2019, d2020)
xTrain = Train[,3:23]
yTrain = Train[,24]
xPredict = d2021[,3:23]
vec1 = colnames(xTrain)
vec2 = paste(vec1, "^2", sep="")
column_names = c(vec1,vec2)
xTrain = cbind(xTrain, xTrain^2)
xPredict = cbind(xPredict, xPredict^2)
colnames(xTrain) = column_names
colnames(xPredict) = column_names
xTrain = xTrain[,-21]# drop yr0fPts since it's a linear combination of 6 other attributes
xPredict = xPredict[,-21]
#choose most important columns
xTrain <- xTrain[c(1,3,4,5,7,11,13,18,21,23,24,25,27,33,41)]
xPredict <- xPredict[c(1,3,4,5,7,11,13,18,21,23,24,25,27,33,41)]
#fit and evaluate the model
a = train(xTrain, log(yTrain))
a # this is the solution to the normal equation
table = attribute_table_2(xTrain, log(yTrain))
table # table of errors; we only care about the first row
#fit and evaluate the model
a = train(xTrain, log(yTrain))
a # this is the solution to the normal equation
# create our train, test, and predict data
d2011 = getdata(2011, positive_y=TRUE)
d2012 = getdata(2012, positive_y=TRUE)
d2013 = getdata(2013, positive_y=TRUE)
d2014 = getdata(2014, positive_y=TRUE)
d2015 = getdata(2015, positive_y=TRUE)
d2016 = getdata(2016, positive_y=TRUE)
d2017 = getdata(2017, positive_y=TRUE)
d2018 = getdata(2018, positive_y=TRUE)
d2019 = getdata(2019, positive_y=TRUE)
d2020 = getdata(2020, positive_y=TRUE)
d2021 = getdata(2021, prediction = TRUE)
Train = rbind(d2011, d2012, d2013, d2014, d2015, d2016, d2017, d2018)
Test = rbind(d2019, d2020)
xTrain = Train[,3:23]
yTrain = Train[,24]
xTest = Test[,3:23]
yTest = Test[,24]
xPredict = d2021[,3:23]
xTrain = xTrain[,-21]
xTest = xTest[,-21]  # drop yr0fPts since it's a linear combination of 6 other attributes
xPredict = xPredict[,-21]
#normalize
constants = matrix(rep(0,40), nrow=20)
X = rbind(xTrain, xTest, xPredict)
for (i in 1:20){
constants[i,] = c(mean(X[,i]),sd(X[,i]))
}
standardization <- function(df) {
for (i in 1:20) {
mean = constants[i,1]
sd = constants[i,2]
df[,i] = (df[,i] - mean) / sd
}
return(df)
}
xTrain <- standardization(xTrain)
xTest <- standardization(xTest)
xPredict <- standardization(xPredict)
#fit and evaluate the model
a = train(xTrain, log(yTrain))
a # this is the solution to the normal equation
# create our train, test, and predict data
d2011 = getdata(2011, positive_y=TRUE)
d2012 = getdata(2012, positive_y=TRUE)
d2013 = getdata(2013, positive_y=TRUE)
d2014 = getdata(2014, positive_y=TRUE)
d2015 = getdata(2015, positive_y=TRUE)
d2016 = getdata(2016, positive_y=TRUE)
d2017 = getdata(2017, positive_y=TRUE)
d2018 = getdata(2018, positive_y=TRUE)
d2019 = getdata(2019, positive_y=TRUE)
d2020 = getdata(2020, positive_y=TRUE)
d2021 = getdata(2021, prediction = TRUE)
Train = rbind(d2011, d2012, d2013, d2014, d2015, d2016, d2017, d2018, d2019, d2020)
xTrain = Train[,3:23]
yTrain = Train[,24]
xPredict = d2021[,3:23]
vec1 = colnames(xTrain)
vec2 = paste(vec1, "^2", sep="")
column_names = c(vec1,vec2)
xTrain = cbind(xTrain, xTrain^2)
xPredict = cbind(xPredict, xPredict^2)
colnames(xTrain) = column_names
colnames(xPredict) = column_names
xTrain = xTrain[,-21]# drop yr0fPts since it's a linear combination of 6 other attributes
xPredict = xPredict[,-21]
#choose most important columns
xTrain <- xTrain[c(1,3,4,5,7,11,13,18,21,23,24,25,27,33,41)]
xPredict <- xPredict[c(1,3,4,5,7,11,13,18,21,23,24,25,27,33,41)]
#fit and evaluate the model
a = train(xTrain, log(yTrain))
a # this is the solution to the normal equation
# create our train, test, and predict data
d2011 = getdata(2011, positive_y=TRUE)
d2012 = getdata(2012, positive_y=TRUE)
d2013 = getdata(2013, positive_y=TRUE)
d2014 = getdata(2014, positive_y=TRUE)
d2015 = getdata(2015, positive_y=TRUE)
d2016 = getdata(2016, positive_y=TRUE)
d2017 = getdata(2017, positive_y=TRUE)
d2018 = getdata(2018, positive_y=TRUE)
d2019 = getdata(2019, positive_y=TRUE)
d2020 = getdata(2020, positive_y=TRUE)
d2021 = getdata(2021, prediction = TRUE)
Train = rbind(d2011, d2012, d2013, d2014, d2015, d2016, d2017, d2018, d2019, d2020)
xTrain = Train[,3:23]
yTrain = Train[,24]
xPredict = d2021[,3:23]
vec1 = colnames(xTrain)
vec2 = paste(vec1, "^2", sep="")
column_names = c(vec1,vec2)
xTrain = cbind(xTrain, xTrain^2)
xPredict = cbind(xPredict, xPredict^2)
colnames(xTrain) = column_names
colnames(xPredict) = column_names
xTrain = xTrain[,-21]# drop yr0fPts since it's a linear combination of 6 other attributes
xPredict = xPredict[,-21]
#choose most important columns
xTrain <- xTrain[c(1,3,4,5,7,11,13,18,21,23,24,25,27,33,41)]
xPredict <- xPredict[c(1,3,4,5,7,11,13,18,21,23,24,25,27,33,41)]
#fit and evaluate the model
a = train(xTrain, log(yTrain))
a # this is the solution to the normal equation
table = attribute_table_2(xTrain, log(yTrain))
table # table of errors; we only care about the first row
#predicting
X=as.matrix(cbind(rep(1,nrow(xPredict)),xPredict))
yHat = X %*% a
prediction = cbind(d2021[,1], exp(yHat))
colnames(prediction) <- c("Name", "ProjPts")
prediction = as.data.frame(prediction)
prediction[,2]<-as.numeric(prediction[,2])
prediction[rev(order(prediction$ProjPts)),] #prediction on 2021 data
